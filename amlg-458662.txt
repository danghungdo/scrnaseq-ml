Start Time : Do 9. Jan 18:15:49 CET 2025
Job ID: 458662
Node: cc2g04
Partition: gpu_normal_stud
CPU cores: 8
GPUs: 0
Memory: 65536
Python environment: amlg_env              *  /home/phamanh/anaconda3/envs/amlg_env
current work directory: /home/phamanh/nobackup/scrnaseq-ml

[I 2025-01-09 18:15:53,896] A new study created in memory with name: no-name-fdc5083e-2711-42f8-8264-9400cd985738
[I 2025-01-09 18:15:59,954] Trial 0 finished with value: 0.732927925050257 and parameters: {'max_depth': 3, 'min_child_weight': 1, 'subsample': 1.0, 'colsample_bytree': 0.8, 'learning_rate': 0.1}. Best is trial 0 with value: 0.732927925050257.
[I 2025-01-09 18:16:11,076] Trial 1 finished with value: 0.7441927337853208 and parameters: {'max_depth': 5, 'min_child_weight': 5, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.3}. Best is trial 1 with value: 0.7441927337853208.
[I 2025-01-09 18:16:22,559] Trial 2 finished with value: 0.7481110441264263 and parameters: {'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.6, 'learning_rate': 0.1}. Best is trial 2 with value: 0.7481110441264263.
[I 2025-01-09 18:16:39,576] Trial 3 finished with value: 0.7451724643502369 and parameters: {'max_depth': 7, 'min_child_weight': 3, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.3}. Best is trial 2 with value: 0.7481110441264263.
[I 2025-01-09 18:16:45,227] Trial 4 finished with value: 0.7351671308680847 and parameters: {'max_depth': 3, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'learning_rate': 0.1}. Best is trial 2 with value: 0.7481110441264263.
[I 2025-01-09 18:16:55,410] Trial 5 finished with value: 0.7504200820900985 and parameters: {'max_depth': 5, 'min_child_weight': 5, 'subsample': 1.0, 'colsample_bytree': 0.6, 'learning_rate': 0.3}. Best is trial 5 with value: 0.7504200820900985.
[I 2025-01-09 18:17:07,936] Trial 6 finished with value: 0.745103121739239 and parameters: {'max_depth': 5, 'min_child_weight': 3, 'subsample': 1.0, 'colsample_bytree': 0.8, 'learning_rate': 0.1}. Best is trial 5 with value: 0.7504200820900985.
[I 2025-01-09 18:17:28,616] Trial 7 finished with value: 0.749090529923919 and parameters: {'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.6, 'learning_rate': 0.3}. Best is trial 5 with value: 0.7504200820900985.
[I 2025-01-09 18:17:51,652] Trial 8 finished with value: 0.7515391832257948 and parameters: {'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'learning_rate': 0.3}. Best is trial 8 with value: 0.7515391832257948.
[I 2025-01-09 18:18:16,397] Trial 9 finished with value: 0.746292397695172 and parameters: {'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.6, 'colsample_bytree': 1.0, 'learning_rate': 0.3}. Best is trial 8 with value: 0.7515391832257948.
[I 2025-01-09 18:18:22,382] Trial 10 finished with value: 0.7525891130876896 and parameters: {'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 1.0, 'learning_rate': 0.3}. Best is trial 10 with value: 0.7525891130876896.
[I 2025-01-09 18:18:53,194] Trial 11 finished with value: 0.7057799134551346 and parameters: {'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.6, 'colsample_bytree': 1.0, 'learning_rate': 0.01}. Best is trial 10 with value: 0.7525891130876896.
[I 2025-01-09 18:19:12,492] Trial 12 finished with value: 0.7472009988469006 and parameters: {'max_depth': 7, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.8, 'learning_rate': 0.3}. Best is trial 10 with value: 0.7525891130876896.
[I 2025-01-09 18:19:31,195] Trial 13 finished with value: 0.7465715794180948 and parameters: {'max_depth': 7, 'min_child_weight': 3, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.3}. Best is trial 10 with value: 0.7525891130876896.
[I 2025-01-09 18:20:00,052] Trial 14 finished with value: 0.697243845384335 and parameters: {'max_depth': 7, 'min_child_weight': 5, 'subsample': 1.0, 'colsample_bytree': 1.0, 'learning_rate': 0.01}. Best is trial 10 with value: 0.7525891130876896.
[I 2025-01-09 18:20:05,657] Trial 15 finished with value: 0.7480410651201281 and parameters: {'max_depth': 3, 'min_child_weight': 1, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.3}. Best is trial 10 with value: 0.7525891130876896.
[I 2025-01-09 18:20:32,501] Trial 16 finished with value: 0.7053601128475728 and parameters: {'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 1.0, 'learning_rate': 0.01}. Best is trial 10 with value: 0.7525891130876896.
[I 2025-01-09 18:20:57,439] Trial 17 finished with value: 0.7475511875992991 and parameters: {'max_depth': 7, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.8, 'learning_rate': 0.1}. Best is trial 10 with value: 0.7525891130876896.
[I 2025-01-09 18:21:03,363] Trial 18 finished with value: 0.7515396972373836 and parameters: {'max_depth': 3, 'min_child_weight': 5, 'subsample': 1.0, 'colsample_bytree': 1.0, 'learning_rate': 0.3}. Best is trial 10 with value: 0.7525891130876896.
[I 2025-01-09 18:21:08,166] Trial 19 finished with value: 0.6647772579733601 and parameters: {'max_depth': 3, 'min_child_weight': 5, 'subsample': 1.0, 'colsample_bytree': 0.6, 'learning_rate': 0.01}. Best is trial 10 with value: 0.7525891130876896.
[I 2025-01-09 18:21:22,489] Trial 20 finished with value: 0.7442627617451036 and parameters: {'max_depth': 5, 'min_child_weight': 1, 'subsample': 1.0, 'colsample_bytree': 1.0, 'learning_rate': 0.1}. Best is trial 10 with value: 0.7525891130876896.
[I 2025-01-09 18:21:34,938] Trial 21 finished with value: 0.749720732608479 and parameters: {'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'learning_rate': 0.3}. Best is trial 10 with value: 0.7525891130876896.
[I 2025-01-09 18:21:47,127] Trial 22 finished with value: 0.6942347725902586 and parameters: {'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.01}. Best is trial 10 with value: 0.7525891130876896.
[I 2025-01-09 18:21:59,184] Trial 23 finished with value: 0.7487408796598516 and parameters: {'max_depth': 5, 'min_child_weight': 5, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.1}. Best is trial 10 with value: 0.7525891130876896.
[I 2025-01-09 18:22:03,991] Trial 24 finished with value: 0.664917191509214 and parameters: {'max_depth': 3, 'min_child_weight': 3, 'subsample': 1.0, 'colsample_bytree': 0.6, 'learning_rate': 0.01}. Best is trial 10 with value: 0.7525891130876896.
[I 2025-01-09 18:22:27,530] Trial 25 finished with value: 0.7080187276450852 and parameters: {'max_depth': 7, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.6, 'learning_rate': 0.01}. Best is trial 10 with value: 0.7525891130876896.
[I 2025-01-09 18:22:33,154] Trial 26 finished with value: 0.664567345431208 and parameters: {'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.6, 'colsample_bytree': 1.0, 'learning_rate': 0.01}. Best is trial 10 with value: 0.7525891130876896.
[I 2025-01-09 18:22:39,161] Trial 27 finished with value: 0.7527289731933166 and parameters: {'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.6, 'colsample_bytree': 1.0, 'learning_rate': 0.3}. Best is trial 27 with value: 0.7527289731933166.
[I 2025-01-09 18:22:49,748] Trial 28 finished with value: 0.6943747061261126 and parameters: {'max_depth': 5, 'min_child_weight': 3, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.01}. Best is trial 27 with value: 0.7527289731933166.
[I 2025-01-09 18:23:15,812] Trial 29 finished with value: 0.7494403760019248 and parameters: {'max_depth': 7, 'min_child_weight': 1, 'subsample': 1.0, 'colsample_bytree': 1.0, 'learning_rate': 0.3}. Best is trial 27 with value: 0.7527289731933166.
[I 2025-01-09 18:23:21,005] Trial 30 finished with value: 0.7521698020149744 and parameters: {'max_depth': 3, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.6, 'learning_rate': 0.3}. Best is trial 27 with value: 0.7527289731933166.
[I 2025-01-09 18:23:31,938] Trial 31 finished with value: 0.7472016352422012 and parameters: {'max_depth': 5, 'min_child_weight': 5, 'subsample': 1.0, 'colsample_bytree': 0.6, 'learning_rate': 0.1}. Best is trial 27 with value: 0.7527289731933166.
[I 2025-01-09 18:24:02,877] Trial 32 finished with value: 0.7015817605190636 and parameters: {'max_depth': 7, 'min_child_weight': 1, 'subsample': 1.0, 'colsample_bytree': 0.8, 'learning_rate': 0.01}. Best is trial 27 with value: 0.7527289731933166.
[I 2025-01-09 18:24:08,366] Trial 33 finished with value: 0.661279041960724 and parameters: {'max_depth': 3, 'min_child_weight': 1, 'subsample': 1.0, 'colsample_bytree': 0.8, 'learning_rate': 0.01}. Best is trial 27 with value: 0.7527289731933166.
[I 2025-01-09 18:24:21,622] Trial 34 finished with value: 0.7456625621617468 and parameters: {'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'learning_rate': 0.1}. Best is trial 27 with value: 0.7527289731933166.
[I 2025-01-09 18:24:33,102] Trial 35 finished with value: 0.7481808028420435 and parameters: {'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.3}. Best is trial 27 with value: 0.7527289731933166.
[I 2025-01-09 18:24:39,019] Trial 36 finished with value: 0.6644974153783945 and parameters: {'max_depth': 3, 'min_child_weight': 1, 'subsample': 0.6, 'colsample_bytree': 1.0, 'learning_rate': 0.01}. Best is trial 27 with value: 0.7527289731933166.
[I 2025-01-09 18:24:53,179] Trial 37 finished with value: 0.685418592680328 and parameters: {'max_depth': 5, 'min_child_weight': 1, 'subsample': 1.0, 'colsample_bytree': 1.0, 'learning_rate': 0.01}. Best is trial 27 with value: 0.7527289731933166.
[I 2025-01-09 18:25:06,969] Trial 38 finished with value: 0.7490207712083017 and parameters: {'max_depth': 5, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 1.0, 'learning_rate': 0.1}. Best is trial 27 with value: 0.7527289731933166.
[I 2025-01-09 18:25:30,939] Trial 39 finished with value: 0.7437728842242745 and parameters: {'max_depth': 7, 'min_child_weight': 5, 'subsample': 1.0, 'colsample_bytree': 0.8, 'learning_rate': 0.1}. Best is trial 27 with value: 0.7527289731933166.
[I 2025-01-09 18:25:43,740] Trial 40 finished with value: 0.7479713553579956 and parameters: {'max_depth': 5, 'min_child_weight': 1, 'subsample': 1.0, 'colsample_bytree': 0.8, 'learning_rate': 0.3}. Best is trial 27 with value: 0.7527289731933166.
[I 2025-01-09 18:26:08,636] Trial 41 finished with value: 0.7481808762722705 and parameters: {'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.1}. Best is trial 27 with value: 0.7527289731933166.
[I 2025-01-09 18:26:33,425] Trial 42 finished with value: 0.7059199938514423 and parameters: {'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 0.8, 'learning_rate': 0.01}. Best is trial 27 with value: 0.7527289731933166.
[I 2025-01-09 18:26:58,699] Trial 43 finished with value: 0.7043103053693895 and parameters: {'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.01}. Best is trial 27 with value: 0.7527289731933166.
[I 2025-01-09 18:27:24,968] Trial 44 finished with value: 0.7022815750587871 and parameters: {'max_depth': 7, 'min_child_weight': 5, 'subsample': 1.0, 'colsample_bytree': 0.8, 'learning_rate': 0.01}. Best is trial 27 with value: 0.7527289731933166.
[I 2025-01-09 18:27:35,677] Trial 45 finished with value: 0.6940249824318181 and parameters: {'max_depth': 5, 'min_child_weight': 5, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.01}. Best is trial 27 with value: 0.7527289731933166.
[I 2025-01-09 18:27:53,629] Trial 46 finished with value: 0.7471317786196146 and parameters: {'max_depth': 7, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.6, 'learning_rate': 0.3}. Best is trial 27 with value: 0.7527289731933166.
[I 2025-01-09 18:27:58,735] Trial 47 finished with value: 0.6665263904564201 and parameters: {'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 0.6, 'learning_rate': 0.01}. Best is trial 27 with value: 0.7527289731933166.
[I 2025-01-09 18:28:22,727] Trial 48 finished with value: 0.7490207712083017 and parameters: {'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.6, 'colsample_bytree': 1.0, 'learning_rate': 0.1}. Best is trial 27 with value: 0.7527289731933166.
[I 2025-01-09 18:28:56,191] Trial 49 finished with value: 0.7425839019892494 and parameters: {'max_depth': 7, 'min_child_weight': 1, 'subsample': 1.0, 'colsample_bytree': 1.0, 'learning_rate': 0.1}. Best is trial 27 with value: 0.7527289731933166.
[I 2025-01-09 18:29:07,639] Trial 50 finished with value: 0.7516095783367123 and parameters: {'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.6, 'learning_rate': 0.3}. Best is trial 27 with value: 0.7527289731933166.
[I 2025-01-09 18:29:31,583] Trial 51 finished with value: 0.7481110930799109 and parameters: {'max_depth': 7, 'min_child_weight': 1, 'subsample': 1.0, 'colsample_bytree': 0.8, 'learning_rate': 0.3}. Best is trial 27 with value: 0.7527289731933166.
[I 2025-01-09 18:29:59,956] Trial 52 finished with value: 0.7028411623417488 and parameters: {'max_depth': 7, 'min_child_weight': 3, 'subsample': 1.0, 'colsample_bytree': 0.8, 'learning_rate': 0.01}. Best is trial 27 with value: 0.7527289731933166.
[I 2025-01-09 18:30:11,906] Trial 53 finished with value: 0.6939547586580967 and parameters: {'max_depth': 5, 'min_child_weight': 5, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.01}. Best is trial 27 with value: 0.7527289731933166.
[I 2025-01-09 18:30:17,833] Trial 54 finished with value: 0.738875357329842 and parameters: {'max_depth': 3, 'min_child_weight': 3, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.1}. Best is trial 27 with value: 0.7527289731933166.
[I 2025-01-09 18:30:23,345] Trial 55 finished with value: 0.7341175436805825 and parameters: {'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.1}. Best is trial 27 with value: 0.7527289731933166.
[I 2025-01-09 18:30:37,043] Trial 56 finished with value: 0.6863981274313053 and parameters: {'max_depth': 5, 'min_child_weight': 5, 'subsample': 1.0, 'colsample_bytree': 1.0, 'learning_rate': 0.01}. Best is trial 27 with value: 0.7527289731933166.
[I 2025-01-09 18:30:55,297] Trial 57 finished with value: 0.7498604703303944 and parameters: {'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 0.8, 'learning_rate': 0.3}. Best is trial 27 with value: 0.7527289731933166.
[I 2025-01-09 18:31:12,934] Trial 58 finished with value: 0.7483211524825168 and parameters: {'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.3}. Best is trial 27 with value: 0.7527289731933166.
[I 2025-01-09 18:31:18,939] Trial 59 finished with value: 0.6584799551390267 and parameters: {'max_depth': 3, 'min_child_weight': 5, 'subsample': 1.0, 'colsample_bytree': 1.0, 'learning_rate': 0.01}. Best is trial 27 with value: 0.7527289731933166.
[I 2025-01-09 18:31:25,304] Trial 60 finished with value: 0.7510496483793582 and parameters: {'max_depth': 3, 'min_child_weight': 3, 'subsample': 1.0, 'colsample_bytree': 1.0, 'learning_rate': 0.3}. Best is trial 27 with value: 0.7527289731933166.
[I 2025-01-09 18:31:38,727] Trial 61 finished with value: 0.7488808131957055 and parameters: {'max_depth': 5, 'min_child_weight': 3, 'subsample': 1.0, 'colsample_bytree': 1.0, 'learning_rate': 0.3}. Best is trial 27 with value: 0.7527289731933166.
[I 2025-01-09 18:31:45,160] Trial 62 finished with value: 0.7514693755566929 and parameters: {'max_depth': 3, 'min_child_weight': 1, 'subsample': 1.0, 'colsample_bytree': 1.0, 'learning_rate': 0.3}. Best is trial 27 with value: 0.7527289731933166.
[I 2025-01-09 18:32:15,087] Trial 63 finished with value: 0.705570270157148 and parameters: {'max_depth': 7, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 1.0, 'learning_rate': 0.01}. Best is trial 27 with value: 0.7527289731933166.
[I 2025-01-09 18:32:27,855] Trial 64 finished with value: 0.7451028524950734 and parameters: {'max_depth': 5, 'min_child_weight': 5, 'subsample': 1.0, 'colsample_bytree': 1.0, 'learning_rate': 0.3}. Best is trial 27 with value: 0.7527289731933166.
[I 2025-01-09 18:32:41,430] Trial 65 finished with value: 0.748601190891421 and parameters: {'max_depth': 5, 'min_child_weight': 5, 'subsample': 0.6, 'colsample_bytree': 1.0, 'learning_rate': 0.1}. Best is trial 27 with value: 0.7527289731933166.
[I 2025-01-09 18:32:54,262] Trial 66 finished with value: 0.7511194805252023 and parameters: {'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.3}. Best is trial 27 with value: 0.7527289731933166.
[I 2025-01-09 18:33:05,160] Trial 67 finished with value: 0.6943046292128451 and parameters: {'max_depth': 5, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 0.6, 'learning_rate': 0.01}. Best is trial 27 with value: 0.7527289731933166.
[I 2025-01-09 18:33:10,643] Trial 68 finished with value: 0.6613490943972492 and parameters: {'max_depth': 3, 'min_child_weight': 5, 'subsample': 1.0, 'colsample_bytree': 0.8, 'learning_rate': 0.01}. Best is trial 27 with value: 0.7527289731933166.
[I 2025-01-09 18:33:39,557] Trial 69 finished with value: 0.7412543742998122 and parameters: {'max_depth': 7, 'min_child_weight': 3, 'subsample': 1.0, 'colsample_bytree': 1.0, 'learning_rate': 0.1}. Best is trial 27 with value: 0.7527289731933166.
[I 2025-01-09 18:34:01,054] Trial 70 finished with value: 0.7482508797553109 and parameters: {'max_depth': 7, 'min_child_weight': 1, 'subsample': 1.0, 'colsample_bytree': 0.6, 'learning_rate': 0.3}. Best is trial 27 with value: 0.7527289731933166.
[I 2025-01-09 18:34:06,319] Trial 71 finished with value: 0.6671562015131032 and parameters: {'max_depth': 3, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.6, 'learning_rate': 0.01}. Best is trial 27 with value: 0.7527289731933166.
[I 2025-01-09 18:34:12,431] Trial 72 finished with value: 0.7364963893133564 and parameters: {'max_depth': 3, 'min_child_weight': 1, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.1}. Best is trial 27 with value: 0.7527289731933166.
[I 2025-01-09 18:34:17,964] Trial 73 finished with value: 0.7534980569138108 and parameters: {'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 0.6, 'learning_rate': 0.3}. Best is trial 73 with value: 0.7534980569138108.
[I 2025-01-09 18:34:24,030] Trial 74 finished with value: 0.7322284042314412 and parameters: {'max_depth': 3, 'min_child_weight': 5, 'subsample': 1.0, 'colsample_bytree': 0.8, 'learning_rate': 0.1}. Best is trial 73 with value: 0.7534980569138108.
[I 2025-01-09 18:34:44,816] Trial 75 finished with value: 0.7469916492698221 and parameters: {'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 0.6, 'learning_rate': 0.1}. Best is trial 73 with value: 0.7534980569138108.
[I 2025-01-09 18:34:55,396] Trial 76 finished with value: 0.74692152340307 and parameters: {'max_depth': 5, 'min_child_weight': 3, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.3}. Best is trial 73 with value: 0.7534980569138108.
[I 2025-01-09 18:35:18,901] Trial 77 finished with value: 0.7059900707647098 and parameters: {'max_depth': 7, 'min_child_weight': 5, 'subsample': 1.0, 'colsample_bytree': 0.6, 'learning_rate': 0.01}. Best is trial 73 with value: 0.7534980569138108.
[I 2025-01-09 18:35:31,270] Trial 78 finished with value: 0.6938848286052833 and parameters: {'max_depth': 5, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 0.8, 'learning_rate': 0.01}. Best is trial 73 with value: 0.7534980569138108.
[I 2025-01-09 18:35:44,035] Trial 79 finished with value: 0.6901066476139704 and parameters: {'max_depth': 5, 'min_child_weight': 1, 'subsample': 1.0, 'colsample_bytree': 0.8, 'learning_rate': 0.01}. Best is trial 73 with value: 0.7534980569138108.
[I 2025-01-09 18:35:57,427] Trial 80 finished with value: 0.7516795818197528 and parameters: {'max_depth': 5, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 1.0, 'learning_rate': 0.3}. Best is trial 73 with value: 0.7534980569138108.
[I 2025-01-09 18:36:08,956] Trial 81 finished with value: 0.7453126426535138 and parameters: {'max_depth': 5, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.6, 'learning_rate': 0.1}. Best is trial 73 with value: 0.7534980569138108.
[I 2025-01-09 18:36:20,117] Trial 82 finished with value: 0.6943745592656586 and parameters: {'max_depth': 5, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.6, 'learning_rate': 0.01}. Best is trial 73 with value: 0.7534980569138108.
[I 2025-01-09 18:36:25,343] Trial 83 finished with value: 0.6683455264225209 and parameters: {'max_depth': 3, 'min_child_weight': 3, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.01}. Best is trial 73 with value: 0.7534980569138108.
[I 2025-01-09 18:36:31,333] Trial 84 finished with value: 0.7534991583672153 and parameters: {'max_depth': 3, 'min_child_weight': 1, 'subsample': 1.0, 'colsample_bytree': 0.8, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:36:51,853] Trial 85 finished with value: 0.7066894936765561 and parameters: {'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:36:57,480] Trial 86 finished with value: 0.7357266202440771 and parameters: {'max_depth': 3, 'min_child_weight': 3, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:37:03,911] Trial 87 finished with value: 0.7502802464612138 and parameters: {'max_depth': 3, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 1.0, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:37:09,452] Trial 88 finished with value: 0.7501401660649059 and parameters: {'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:37:14,957] Trial 89 finished with value: 0.7499303759064655 and parameters: {'max_depth': 3, 'min_child_weight': 1, 'subsample': 1.0, 'colsample_bytree': 0.6, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:37:50,275] Trial 90 finished with value: 0.6945147375689358 and parameters: {'max_depth': 7, 'min_child_weight': 1, 'subsample': 1.0, 'colsample_bytree': 1.0, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:38:18,400] Trial 91 finished with value: 0.7474110337727643 and parameters: {'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:38:45,016] Trial 92 finished with value: 0.7082983744261122 and parameters: {'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.6, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:39:18,647] Trial 93 finished with value: 0.7050103157230515 and parameters: {'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 1.0, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:39:25,137] Trial 94 finished with value: 0.7305490794174829 and parameters: {'max_depth': 3, 'min_child_weight': 1, 'subsample': 1.0, 'colsample_bytree': 1.0, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:39:30,779] Trial 95 finished with value: 0.7484607188672359 and parameters: {'max_depth': 3, 'min_child_weight': 1, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:39:37,253] Trial 96 finished with value: 0.7321584986553702 and parameters: {'max_depth': 3, 'min_child_weight': 3, 'subsample': 1.0, 'colsample_bytree': 1.0, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:39:54,171] Trial 97 finished with value: 0.7478308833338106 and parameters: {'max_depth': 7, 'min_child_weight': 5, 'subsample': 1.0, 'colsample_bytree': 0.6, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:40:14,370] Trial 98 finished with value: 0.7476914393328031 and parameters: {'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:40:34,767] Trial 99 finished with value: 0.7484609636346591 and parameters: {'max_depth': 7, 'min_child_weight': 3, 'subsample': 1.0, 'colsample_bytree': 0.8, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:40:40,739] Trial 100 finished with value: 0.6621884508449494 and parameters: {'max_depth': 3, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 1.0, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:40:53,396] Trial 101 finished with value: 0.7453127160837407 and parameters: {'max_depth': 5, 'min_child_weight': 5, 'subsample': 1.0, 'colsample_bytree': 0.8, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:40:58,981] Trial 102 finished with value: 0.661208989524199 and parameters: {'max_depth': 3, 'min_child_weight': 3, 'subsample': 1.0, 'colsample_bytree': 0.8, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:41:23,080] Trial 103 finished with value: 0.7488107852359227 and parameters: {'max_depth': 7, 'min_child_weight': 3, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:41:29,131] Trial 104 finished with value: 0.7509798407102563 and parameters: {'max_depth': 3, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:41:49,388] Trial 105 finished with value: 0.751819613262576 and parameters: {'max_depth': 7, 'min_child_weight': 5, 'subsample': 1.0, 'colsample_bytree': 1.0, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:42:01,970] Trial 106 finished with value: 0.7471317051893875 and parameters: {'max_depth': 5, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 0.8, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:42:13,591] Trial 107 finished with value: 0.7453125447465446 and parameters: {'max_depth': 5, 'min_child_weight': 3, 'subsample': 1.0, 'colsample_bytree': 0.6, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:42:24,896] Trial 108 finished with value: 0.6940250313853029 and parameters: {'max_depth': 5, 'min_child_weight': 3, 'subsample': 1.0, 'colsample_bytree': 0.6, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:42:30,538] Trial 109 finished with value: 0.7349570225119942 and parameters: {'max_depth': 3, 'min_child_weight': 1, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:42:53,753] Trial 110 finished with value: 0.7472015862887164 and parameters: {'max_depth': 7, 'min_child_weight': 3, 'subsample': 1.0, 'colsample_bytree': 0.6, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:43:00,174] Trial 111 finished with value: 0.7525892599481436 and parameters: {'max_depth': 3, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 1.0, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:43:27,903] Trial 112 finished with value: 0.706199934353377 and parameters: {'max_depth': 7, 'min_child_weight': 1, 'subsample': 1.0, 'colsample_bytree': 0.6, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:43:46,512] Trial 113 finished with value: 0.7479714043114802 and parameters: {'max_depth': 7, 'min_child_weight': 5, 'subsample': 1.0, 'colsample_bytree': 0.8, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:44:12,434] Trial 114 finished with value: 0.7446821217713036 and parameters: {'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.6, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:44:18,870] Trial 115 finished with value: 0.7515404560163955 and parameters: {'max_depth': 3, 'min_child_weight': 3, 'subsample': 0.6, 'colsample_bytree': 1.0, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:44:40,486] Trial 116 finished with value: 0.7519591306938105 and parameters: {'max_depth': 7, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 1.0, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:44:46,543] Trial 117 finished with value: 0.7516092846158046 and parameters: {'max_depth': 3, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.8, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:45:00,416] Trial 118 finished with value: 0.6915058850655402 and parameters: {'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6, 'colsample_bytree': 1.0, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:45:05,915] Trial 119 finished with value: 0.753219487109446 and parameters: {'max_depth': 3, 'min_child_weight': 5, 'subsample': 1.0, 'colsample_bytree': 0.6, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:45:19,473] Trial 120 finished with value: 0.6897566301987682 and parameters: {'max_depth': 5, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 1.0, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:45:24,701] Trial 121 finished with value: 0.6651271040513659 and parameters: {'max_depth': 3, 'min_child_weight': 1, 'subsample': 1.0, 'colsample_bytree': 0.6, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:45:30,255] Trial 122 finished with value: 0.750070505256258 and parameters: {'max_depth': 3, 'min_child_weight': 3, 'subsample': 1.0, 'colsample_bytree': 0.6, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:45:44,480] Trial 123 finished with value: 0.7489506942950342 and parameters: {'max_depth': 5, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 1.0, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:45:58,763] Trial 124 finished with value: 0.7490210159757249 and parameters: {'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 1.0, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:46:10,155] Trial 125 finished with value: 0.7476211666055972 and parameters: {'max_depth': 5, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 0.6, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:46:16,656] Trial 126 finished with value: 0.7343978023801674 and parameters: {'max_depth': 3, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 1.0, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:46:27,981] Trial 127 finished with value: 0.6954240974996763 and parameters: {'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.6, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:46:34,009] Trial 128 finished with value: 0.750979889663741 and parameters: {'max_depth': 3, 'min_child_weight': 3, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:46:57,236] Trial 129 finished with value: 0.7483208098081244 and parameters: {'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:47:03,325] Trial 130 finished with value: 0.7366363228492103 and parameters: {'max_depth': 3, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.8, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:47:17,345] Trial 131 finished with value: 0.6863979805708516 and parameters: {'max_depth': 5, 'min_child_weight': 3, 'subsample': 1.0, 'colsample_bytree': 1.0, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:47:29,853] Trial 132 finished with value: 0.6894770568479683 and parameters: {'max_depth': 5, 'min_child_weight': 5, 'subsample': 1.0, 'colsample_bytree': 0.8, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:47:41,582] Trial 133 finished with value: 0.7523091236322703 and parameters: {'max_depth': 5, 'min_child_weight': 5, 'subsample': 1.0, 'colsample_bytree': 0.8, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:47:53,958] Trial 134 finished with value: 0.694024811094622 and parameters: {'max_depth': 5, 'min_child_weight': 3, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:48:05,974] Trial 135 finished with value: 0.750770050551816 and parameters: {'max_depth': 5, 'min_child_weight': 3, 'subsample': 1.0, 'colsample_bytree': 0.8, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:48:18,755] Trial 136 finished with value: 0.7495806032586866 and parameters: {'max_depth': 5, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 1.0, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:48:24,830] Trial 137 finished with value: 0.7306192297609773 and parameters: {'max_depth': 3, 'min_child_weight': 3, 'subsample': 1.0, 'colsample_bytree': 0.8, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:48:30,077] Trial 138 finished with value: 0.6682755963697075 and parameters: {'max_depth': 3, 'min_child_weight': 1, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:48:42,572] Trial 139 finished with value: 0.6938147761687583 and parameters: {'max_depth': 5, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.8, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:48:55,203] Trial 140 finished with value: 0.6900367665146416 and parameters: {'max_depth': 5, 'min_child_weight': 3, 'subsample': 1.0, 'colsample_bytree': 0.8, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:49:05,700] Trial 141 finished with value: 0.7434231850067224 and parameters: {'max_depth': 5, 'min_child_weight': 5, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:49:28,293] Trial 142 finished with value: 0.7470615793226355 and parameters: {'max_depth': 7, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.6, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:49:49,641] Trial 143 finished with value: 0.7469916982233067 and parameters: {'max_depth': 7, 'min_child_weight': 3, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:49:55,281] Trial 144 finished with value: 0.662887751373084 and parameters: {'max_depth': 3, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.8, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:50:14,225] Trial 145 finished with value: 0.7476211910823395 and parameters: {'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.6, 'colsample_bytree': 1.0, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:50:19,850] Trial 146 finished with value: 0.7507698547378773 and parameters: {'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:50:44,488] Trial 147 finished with value: 0.7067596440200504 and parameters: {'max_depth': 7, 'min_child_weight': 3, 'subsample': 1.0, 'colsample_bytree': 0.6, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:51:09,524] Trial 148 finished with value: 0.7492306592737114 and parameters: {'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 1.0, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:51:15,036] Trial 149 finished with value: 0.7527297319723285 and parameters: {'max_depth': 3, 'min_child_weight': 5, 'subsample': 1.0, 'colsample_bytree': 0.8, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:51:30,589] Trial 150 finished with value: 0.7464309605334558 and parameters: {'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:52:00,238] Trial 151 finished with value: 0.7086485631785105 and parameters: {'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:52:25,859] Trial 152 finished with value: 0.7433533039073937 and parameters: {'max_depth': 7, 'min_child_weight': 3, 'subsample': 1.0, 'colsample_bytree': 0.8, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:52:46,288] Trial 153 finished with value: 0.7491608271278671 and parameters: {'max_depth': 7, 'min_child_weight': 3, 'subsample': 0.6, 'colsample_bytree': 1.0, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:53:05,568] Trial 154 finished with value: 0.7512595853982524 and parameters: {'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 1.0, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:53:10,432] Trial 155 finished with value: 0.6684155543823037 and parameters: {'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:53:20,960] Trial 156 finished with value: 0.7493705928095653 and parameters: {'max_depth': 5, 'min_child_weight': 3, 'subsample': 1.0, 'colsample_bytree': 0.6, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:53:26,208] Trial 157 finished with value: 0.6672261560426591 and parameters: {'max_depth': 3, 'min_child_weight': 3, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:53:38,641] Trial 158 finished with value: 0.7453121041651827 and parameters: {'max_depth': 5, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.8, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:53:52,673] Trial 159 finished with value: 0.7506995820106714 and parameters: {'max_depth': 5, 'min_child_weight': 1, 'subsample': 1.0, 'colsample_bytree': 1.0, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:53:58,783] Trial 160 finished with value: 0.7369864136946394 and parameters: {'max_depth': 3, 'min_child_weight': 1, 'subsample': 0.6, 'colsample_bytree': 1.0, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:54:12,362] Trial 161 finished with value: 0.7455927055391602 and parameters: {'max_depth': 5, 'min_child_weight': 5, 'subsample': 1.0, 'colsample_bytree': 1.0, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:54:25,968] Trial 162 finished with value: 0.7482512713831879 and parameters: {'max_depth': 5, 'min_child_weight': 3, 'subsample': 0.6, 'colsample_bytree': 1.0, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:54:32,057] Trial 163 finished with value: 0.734607519108381 and parameters: {'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 1.0, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:54:44,399] Trial 164 finished with value: 0.6933950245146813 and parameters: {'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:55:15,466] Trial 165 finished with value: 0.7493004914195556 and parameters: {'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.6, 'colsample_bytree': 1.0, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:55:26,420] Trial 166 finished with value: 0.6940948880078893 and parameters: {'max_depth': 5, 'min_child_weight': 1, 'subsample': 1.0, 'colsample_bytree': 0.6, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:55:39,289] Trial 167 finished with value: 0.7452426146937311 and parameters: {'max_depth': 5, 'min_child_weight': 1, 'subsample': 1.0, 'colsample_bytree': 0.8, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:56:03,751] Trial 168 finished with value: 0.7074588955947003 and parameters: {'max_depth': 7, 'min_child_weight': 3, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:56:09,136] Trial 169 finished with value: 0.7300591774199116 and parameters: {'max_depth': 3, 'min_child_weight': 5, 'subsample': 1.0, 'colsample_bytree': 0.6, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:56:14,366] Trial 170 finished with value: 0.7492306837504538 and parameters: {'max_depth': 3, 'min_child_weight': 3, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:56:19,981] Trial 171 finished with value: 0.6616987691380588 and parameters: {'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 1.0, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:56:31,101] Trial 172 finished with value: 0.7497905158008387 and parameters: {'max_depth': 5, 'min_child_weight': 1, 'subsample': 1.0, 'colsample_bytree': 0.6, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:56:35,979] Trial 173 finished with value: 0.6672261560426591 and parameters: {'max_depth': 3, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.6, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:56:48,231] Trial 174 finished with value: 0.747830907810553 and parameters: {'max_depth': 5, 'min_child_weight': 3, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:57:02,307] Trial 175 finished with value: 0.7506297988183117 and parameters: {'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6, 'colsample_bytree': 1.0, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:57:13,036] Trial 176 finished with value: 0.7500002814825366 and parameters: {'max_depth': 5, 'min_child_weight': 5, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:57:35,340] Trial 177 finished with value: 0.7066196615307119 and parameters: {'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:57:56,744] Trial 178 finished with value: 0.7492307571806807 and parameters: {'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:58:22,866] Trial 179 finished with value: 0.7494405228623788 and parameters: {'max_depth': 7, 'min_child_weight': 3, 'subsample': 0.6, 'colsample_bytree': 1.0, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:58:33,591] Trial 180 finished with value: 0.6938850244192218 and parameters: {'max_depth': 5, 'min_child_weight': 5, 'subsample': 1.0, 'colsample_bytree': 0.6, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:58:44,980] Trial 181 finished with value: 0.7451022650532577 and parameters: {'max_depth': 5, 'min_child_weight': 1, 'subsample': 1.0, 'colsample_bytree': 0.6, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:59:07,731] Trial 182 finished with value: 0.7485305999665648 and parameters: {'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 0.8, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:59:28,649] Trial 183 finished with value: 0.7458021040697236 and parameters: {'max_depth': 7, 'min_child_weight': 5, 'subsample': 1.0, 'colsample_bytree': 0.6, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:59:34,241] Trial 184 finished with value: 0.6583400705566573 and parameters: {'max_depth': 3, 'min_child_weight': 1, 'subsample': 1.0, 'colsample_bytree': 1.0, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 18:59:58,625] Trial 185 finished with value: 0.7034710957821433 and parameters: {'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.6, 'colsample_bytree': 1.0, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:00:28,041] Trial 186 finished with value: 0.7413235945270984 and parameters: {'max_depth': 7, 'min_child_weight': 1, 'subsample': 1.0, 'colsample_bytree': 0.8, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:00:33,256] Trial 187 finished with value: 0.7337677710328036 and parameters: {'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 0.6, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:00:38,486] Trial 188 finished with value: 0.7334177536176014 and parameters: {'max_depth': 3, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.6, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:01:05,398] Trial 189 finished with value: 0.7057799868853614 and parameters: {'max_depth': 7, 'min_child_weight': 3, 'subsample': 0.6, 'colsample_bytree': 1.0, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:01:11,054] Trial 190 finished with value: 0.7362166446253603 and parameters: {'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:01:16,680] Trial 191 finished with value: 0.6623984368173284 and parameters: {'max_depth': 3, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 1.0, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:01:27,821] Trial 192 finished with value: 0.7505596729515597 and parameters: {'max_depth': 5, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 0.8, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:01:33,023] Trial 193 finished with value: 0.7331379354993782 and parameters: {'max_depth': 3, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.6, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:01:47,202] Trial 194 finished with value: 0.7478316665895649 and parameters: {'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 1.0, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:02:16,070] Trial 195 finished with value: 0.7475514078899799 and parameters: {'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:02:47,820] Trial 196 finished with value: 0.6956343527162208 and parameters: {'max_depth': 7, 'min_child_weight': 3, 'subsample': 1.0, 'colsample_bytree': 1.0, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:03:13,960] Trial 197 finished with value: 0.7434233808206611 and parameters: {'max_depth': 7, 'min_child_weight': 5, 'subsample': 1.0, 'colsample_bytree': 1.0, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:03:27,588] Trial 198 finished with value: 0.7462217578168312 and parameters: {'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6, 'colsample_bytree': 1.0, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:03:32,813] Trial 199 finished with value: 0.7305489815105137 and parameters: {'max_depth': 3, 'min_child_weight': 3, 'subsample': 1.0, 'colsample_bytree': 0.6, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:03:38,421] Trial 200 finished with value: 0.658480053045996 and parameters: {'max_depth': 3, 'min_child_weight': 3, 'subsample': 1.0, 'colsample_bytree': 1.0, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:03:44,002] Trial 201 finished with value: 0.7529392773633458 and parameters: {'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 0.8, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:03:57,871] Trial 202 finished with value: 0.7438431814282229 and parameters: {'max_depth': 5, 'min_child_weight': 3, 'subsample': 1.0, 'colsample_bytree': 1.0, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:04:09,434] Trial 203 finished with value: 0.7453120307349558 and parameters: {'max_depth': 5, 'min_child_weight': 3, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:04:14,644] Trial 204 finished with value: 0.7308291423031293 and parameters: {'max_depth': 3, 'min_child_weight': 1, 'subsample': 1.0, 'colsample_bytree': 0.6, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:04:27,456] Trial 205 finished with value: 0.6914359550127267 and parameters: {'max_depth': 5, 'min_child_weight': 5, 'subsample': 0.6, 'colsample_bytree': 1.0, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:04:55,251] Trial 206 finished with value: 0.7077388850501197 and parameters: {'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:05:00,495] Trial 207 finished with value: 0.6632375729743477 and parameters: {'max_depth': 3, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:05:22,104] Trial 208 finished with value: 0.749720267550375 and parameters: {'max_depth': 7, 'min_child_weight': 3, 'subsample': 1.0, 'colsample_bytree': 1.0, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:05:35,490] Trial 209 finished with value: 0.6900365951774454 and parameters: {'max_depth': 5, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 1.0, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:05:51,595] Trial 210 finished with value: 0.7502099492572655 and parameters: {'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 0.6, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:05:57,625] Trial 211 finished with value: 0.7309691492692101 and parameters: {'max_depth': 3, 'min_child_weight': 5, 'subsample': 1.0, 'colsample_bytree': 1.0, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:06:29,857] Trial 212 finished with value: 0.74783098124078 and parameters: {'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 1.0, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:06:35,504] Trial 213 finished with value: 0.7342575261699209 and parameters: {'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 0.8, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:06:47,195] Trial 214 finished with value: 0.7488105404684996 and parameters: {'max_depth': 5, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.8, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:07:12,568] Trial 215 finished with value: 0.7503504212814505 and parameters: {'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 1.0, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:07:32,771] Trial 216 finished with value: 0.7464317927426949 and parameters: {'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:07:51,048] Trial 217 finished with value: 0.7495098654733765 and parameters: {'max_depth': 7, 'min_child_weight': 3, 'subsample': 1.0, 'colsample_bytree': 0.6, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:08:13,355] Trial 218 finished with value: 0.7075291927986487 and parameters: {'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 0.6, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:08:19,375] Trial 219 finished with value: 0.6643574084123136 and parameters: {'max_depth': 3, 'min_child_weight': 3, 'subsample': 0.6, 'colsample_bytree': 1.0, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:08:24,988] Trial 220 finished with value: 0.6673661140552553 and parameters: {'max_depth': 3, 'min_child_weight': 1, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:08:38,249] Trial 221 finished with value: 0.7430732165450049 and parameters: {'max_depth': 5, 'min_child_weight': 3, 'subsample': 0.6, 'colsample_bytree': 1.0, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:08:51,870] Trial 222 finished with value: 0.6919256367196173 and parameters: {'max_depth': 5, 'min_child_weight': 3, 'subsample': 0.6, 'colsample_bytree': 1.0, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:09:04,507] Trial 223 finished with value: 0.750280638089091 and parameters: {'max_depth': 5, 'min_child_weight': 5, 'subsample': 0.6, 'colsample_bytree': 1.0, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:09:16,368] Trial 224 finished with value: 0.7476914882862878 and parameters: {'max_depth': 5, 'min_child_weight': 3, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:09:22,829] Trial 225 finished with value: 0.734677351254225 and parameters: {'max_depth': 3, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 1.0, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:09:28,336] Trial 226 finished with value: 0.753358661866288 and parameters: {'max_depth': 3, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.6, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:09:34,202] Trial 227 finished with value: 0.7531491654287554 and parameters: {'max_depth': 3, 'min_child_weight': 3, 'subsample': 1.0, 'colsample_bytree': 0.8, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:09:39,766] Trial 228 finished with value: 0.6634475589467266 and parameters: {'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 0.8, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:09:46,180] Trial 229 finished with value: 0.7506299456787657 and parameters: {'max_depth': 3, 'min_child_weight': 1, 'subsample': 0.6, 'colsample_bytree': 1.0, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:09:56,869] Trial 230 finished with value: 0.7502801240775021 and parameters: {'max_depth': 5, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 0.6, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:10:02,419] Trial 231 finished with value: 0.6672261315659167 and parameters: {'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:10:14,148] Trial 232 finished with value: 0.7458025936045699 and parameters: {'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:10:36,797] Trial 233 finished with value: 0.7068294761658945 and parameters: {'max_depth': 7, 'min_child_weight': 3, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:11:05,120] Trial 234 finished with value: 0.7480408693061895 and parameters: {'max_depth': 7, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 1.0, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:11:16,296] Trial 235 finished with value: 0.6938150209361815 and parameters: {'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6, 'colsample_bytree': 0.6, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:11:43,394] Trial 236 finished with value: 0.707249252296714 and parameters: {'max_depth': 7, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.8, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:11:49,780] Trial 237 finished with value: 0.73971500749845 and parameters: {'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.6, 'colsample_bytree': 1.0, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:12:00,640] Trial 238 finished with value: 0.751119676339141 and parameters: {'max_depth': 5, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.6, 'learning_rate': 0.3}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:12:07,027] Trial 239 finished with value: 0.7381056616907897 and parameters: {'max_depth': 3, 'min_child_weight': 3, 'subsample': 0.6, 'colsample_bytree': 1.0, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:12:20,118] Trial 240 finished with value: 0.7492302186923496 and parameters: {'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:12:46,509] Trial 241 finished with value: 0.74181381472232 and parameters: {'max_depth': 7, 'min_child_weight': 1, 'subsample': 1.0, 'colsample_bytree': 0.6, 'learning_rate': 0.1}. Best is trial 84 with value: 0.7534991583672153.
[I 2025-01-09 19:13:00,565] Trial 242 finished with value: 0.6907361894264878 and parameters: {'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 1.0, 'learning_rate': 0.01}. Best is trial 84 with value: 0.7534991583672153.
Number of training samples: 14292
Number of test samples: 3573
Tuning hyperparameters...
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Number of training samples: 14292
Best Hyperparams:  {'max_depth': 3, 'min_child_weight': 1, 'subsample': 1.0, 'colsample_bytree': 0.8, 'learning_rate': 0.3}
Best Accuracy:  0.7534991583672153
saving hyperparameters each trials and best hyperparameters
Best hyperparameters and trials are saved under logs/best_hyperparameters.json and logs/optuna_trials.csv.
Initializing model...
Training model...
Accuracy on training data: 0.8435488385110551
Evaluating model...
Accuracy: 0.7111670864819479
Confusion matrix: [[1014   17   83   37   57   86  177]
 [  11   47    2    0    0    5    3]
 [  50    6   82    4    5   13   11]
 [  62    1    5  392   18   10   21]
 [  32    1    2    4  287   10    2]
 [  60    9   17    2    7  193    3]
 [ 136    4   26   12   12    9  526]]
Classification report:               precision    recall  f1-score   support

           0       0.74      0.69      0.72      1471
           1       0.55      0.69      0.61        68
           2       0.38      0.48      0.42       171
           3       0.87      0.77      0.82       509
           4       0.74      0.85      0.79       338
           5       0.59      0.66      0.63       291
           6       0.71      0.73      0.72       725

    accuracy                           0.71      3573
   macro avg       0.66      0.70      0.67      3573
weighted avg       0.72      0.71      0.71      3573

Number of test samples: 3573

End Time   : Do 9. Jan 19:13:03 CET 2025
Duration   : 3433.693631940 seconds
